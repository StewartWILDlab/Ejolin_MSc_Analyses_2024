---
title: "04_example_richness.R"
output: html_document
date: "2023-07-31"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#README

Another C.Beirne script modified by E.Jolin

Modified to work with outputs from 1_WildRTrax_Data_Download.R

Data exploration mainly regarding community composition, and in relation to environmental covariates

# Load the required packages

```{r}
# Check you have them and load them
list.of.packages <- c("iNEXT", "kableExtra", "tidyr", "ggplot2", "gridExtra", "dplyr", "viridis","stringr")

new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
lapply(list.of.packages, require, character.only = TRUE)
```

# 8.1 Observed richness

The simplest way to quantify species richness is counting the number of species you detect on your camera traps - ‘observed richness’. This is very easy to determine using our species list:

```{r}
sp_summary <- read.csv("Processed_Data/TDN_CAM_Species_List_v14.csv", header=T)

sp_rank<-read.csv("Raw_Data/TDN_CAM_Species_rank_class_v2.csv")

sp_summary<-left_join(sp_summary,sp_rank)

#change formatting to get the two sets to work together  
sp_summary$species_common_name<-str_replace_all(sp_summary$species_common_name, " ", ".")
sp_summary$species_common_name<-str_replace_all(sp_summary$species_common_name, "-", ".")
sp_summary$species_common_name<-str_replace_all(sp_summary$species_common_name, "'", ".")


# Use nrow() to count the number of species
nrow(sp_summary)

#subset sp_summary to mammals
sp_summary_tmp <- subset(sp_summary, sp_summary$species_class == "Mammalia") #subset to mammals
sp_summary_mam <- subset(sp_summary_tmp, sp_summary_tmp$species_scientific_name != "Homo sapiens") #remove humans

# Use nrow() to count the number of species
nrow(sp_summary_mam)

rm(sp_summary_tmp) #clean up
```

It is possible to compare observed richness across different strata of interest, however survey effort must be identical between your comparison strata. This very rarely the case in camera trap studies where cameras break, run out of battery or are deployed for different lengths of time.

The number of species you detect is a function of the amount of effort you spent surveying/the number of individuals detected - the longer a camera is active/the more individuals detected, the more species it will detect. What this means is, unless you saturate a landscape with camera traps, observed richness will underestimate true richness. Consequently, We need ways of comparing species richness which accounts in some way for survey effort.

# 8.2 Estimated richness

There are two commonly used ways to account for survey effort when estimating species richness using camera traps:

i.using the incidence of rare species to ‘correct’ observed richness (iNext)
ii.using multispecies occupancy models to account for the species present but not observed (occupancy model)

## 8.2.1 iNext package

The iNext package (INterpolation and EXTrapolation of species richness) - is both easy to use and rapid to compute. It also comes with a wealth of plotting functions - see the iNext Quick Introduction for a great walk through tutorial. Its core functionality is based on:

Chao, Anne, et al. “Rarefaction and extrapolation with Hill numbers: a framework for sampling and estimation in species diversity studies.” Ecological monographs 84.1 (2014): 45-67. Which has, to date, been cited >2000 times!

To run this example code you will need to load the iNEXT , ggplot2, and gridExtra packages.

```{r}
library(iNEXT); library(ggplot2); library(gridExtra)
```

Single strata

You may want to see if your camera project has sufficient survey effort to capture the species within the area of interest. To do this we can compute a species accumulation curves across the site as a whole. Species accumulation curves plot the increase in species richness as we add survey units. If the curve plateaus (flattens), then that suggests you have sampled the majority of the species in your survey area.

# 8.3 Sampling-unit-based accumulation curves

In camera trap projects we typically do not think about our survey effort in terms of the number of camera stations we deploy on the landscape or the units of time they are active (e.g. camera days).

Performing our species accumulation curves using survey location allows us to determine if we have enough survey locations in a given strata to detect all of the species present. Repeating the analyses using camera days would also give insight into whether we need for survey effort in a given location.

## 8.3.1 Data formatting

The data formatting for a sampling-unit based accumulation curve is as follows: we need a list of strata then the elements in that list first represent the number of sampling units surveyed, then the number of those units where each given species was detected following it.

The example that comes with the iNext package looks like this.
https://wildcolab.github.io/Introduction-to-Camera-Trap-Data-Management-and-Analysis-in-R/images/community_metrics/unit_based.png

We can create this format from the total observations file:

```{r}
total_obs <- read.csv("Processed_Data/wildRtrax/TDN_cam_summaries_full_mam.csv", header=T)

inc_dat <- total_obs %>% 
      mutate(across(sp_summary_mam$species_common_name, ~+as.logical(.x)))  # Turn species counts into 0's and 1's

# Make an empty list to store our data
project_level <- list()
# Sum all of the observations of each species (colSums), and then make it an element within the project_level list
 project_level[[1]] <-  c(nrow(inc_dat),  # First count the number of stations
                     # Then subset the detections to those stations, sum the columns, and sort the incidents
                     inc_dat[, sp_summary_mam$species_common_name] %>%  colSums() %>% sort(decreasing=T))
# # Give it a name
names(project_level) <- "project_level"

project_level
```

## 8.3.2 iNext model
And let’s run our iNext model:

```{r}
out <- iNEXT(project_level,          # The data frame
             q=0,                    # The type of diversity estimator (see discussion of the options below)
             datatype="incidence_freq",   # The type of analysis
             knots=40,                    # The number of data points in your line (more = smoother)
             se=TRUE,                     # Logical statement if you want confidence intervals
             conf=0.95,                   # The level of confidence intervals
             nboot=50)                    # The number of replications to perform - this generates your confidence interval - the bigger the number the longer the run time

```

a note on q values

The iNEXT package uses the concept of hill numbers to calculate its community indices. The q values reflect traditional diversity estimators:

0 = species richness
1 = Shannon diversity
2 = Simpson diversity
They differ in the weighting of rare species. 0 treats the ‘value’ of every species equally, rare or common. As the the q value increases, the influence of rare species becomes weaker and weaker.

a note on coverage

Whilst many users will be familiar with diversity indices, iNEXT also calculates ‘sample coverage’ - the proportion of the total number of individuals that belong to the species detected in the sample. The way to conceptualize this is - if you add an un-surveyed individual to the surveyed population, what is the likelihood it belongs to the species not already detected? If your sample coverage is high, this probability will be very low!

We will start with observed richness.

The iNEXT() function returns the “iNEXT” object including three output lists: - $DataInfo for summarizing data information - $iNextEst for showing size- and coverage-based diversity estimates along with related statistics for a series of rarefied and extrapolated samples - $AsyEst for showing asymptotic diversity estimates along with related statistics.

```{r}
out
```

$DataInfo is shown below, returns summary data such as the reference sample size (T), observed species richness (S.obs - which is hopefully the same as what we calculated above), sample coverage estimate for the reference sample (SC), and the first ten frequency counts (q1-q10).

Compare 1 assemblages with Hill number order q = 0.
$class: iNEXT

$DataInfo: basic data information
     Assemblage   T    U S.obs     SC Q1 Q2 Q3 Q4 Q5 Q6 Q7 Q8 Q9 Q10
1 project_level 307 1039    20 0.9971  3  0  1  1  0  0  0  0  0   0

$iNextEst output includes two data frames: $size_based and $coverage_based.

### 8.3.2.1 Let’s first look at $iNextEst$size_based:

$iNextEst: diversity estimates with rarefied and extrapolated samples.
$size_based (LCL and UCL are obtained for fixed size.)

         Assemblage   t        Method Order.q        qD    qD.LCL    qD.UCL        SC    SC.LCL    SC.UCL
1  project_level   1   Rarefaction       0  3.384365  3.209829  3.558901 0.3194185 0.3014876 0.3373494
10 project_level 153   Rarefaction       0 18.307825 16.901189 19.714462 0.9959119 0.9937926 0.9980311
20 project_level 307      Observed       0 20.000000 17.990269 22.009731 0.9971220 0.9947812 0.9994628
30 project_level 452 Extrapolation       0 21.127083 18.481503 23.772663 0.9982068 0.9965125 0.9999011
40 project_level 614 Extrapolation       0 21.891979 18.629378 25.154579 0.9989430 0.9977652 1.0000000

NOTE: The above output only shows five estimates for each assemblage; call iNEXT.object$iNextEst$size_based to view complete output.

### 8.3.2.2 Next $iNextEst$coverage_based:

$coverage_based (LCL and UCL are obtained for fixed coverage; interval length is wider due to varying size in bootstraps.)

      Assemblage        SC   t        Method Order.q        qD    qD.LCL    qD.UCL
1  project_level 0.3194215   1   Rarefaction       0  3.384395  3.228487  3.540302
10 project_level 0.9959119 153   Rarefaction       0 18.307825 15.823692 20.791959
20 project_level 0.9971220 307      Observed       0 20.000000 16.875383 23.124617
30 project_level 0.9982068 452 Extrapolation       0 21.127083 17.522961 24.731204
40 project_level 0.9989430 614 Extrapolation       0 21.891979 17.826974 25.956984

NOTE: The above output only shows five estimates for each assemblage; call iNEXT.object$iNextEst$coverage_based to view complete output.

### 8.3.2.3 $AsyEst gives the asymptotic estimates and their related statistics.

$AsyEst: asymptotic diversity estimates along with related statistics.
     Assemblage         Diversity Observed Estimator      s.e.      LCL      UCL
1 project_level  Species richness 20.00000  22.99023 2.7960895 20.00000 28.47046
2 project_level Shannon diversity 12.75019  12.87849 0.2380403 12.41194 13.34504
3 project_level Simpson diversity 10.52237  10.59539 0.2750136 10.05638 11.13441

One of the powerful elements of iNEXT is that it can extrapolate beyond your data, this is very useful when you do not have equal sample sizes.

#8.4 Basic results plot

```{r}
p1 <- ggiNEXT(out, type=1)+ theme_classic() +   #  type 1 = the diversity estimator
        labs(x = "Number of Cameras", y = "Richness")
  
  p2 <- ggiNEXT(out, type=2)+ theme_classic() +    #  type 2 = the survey coverage
        labs(x = "Number of Cameras")
    
    grid.arrange(p1, p2, nrow = 1)
```

Multiple strata

The iNEXT package gets really interesting when we start to compare multiple different strata. e.g. different treatment types or species groupings.

The code to build a multi strata comparison is very similar to that of a single strata, except now you separate the observations into their relevant categories.

We will compare the different categories using the feature_type column in the covariate file. We match the ‘placenames’ in our locations dataframe with the corresponding capture data in total_obs using the %in% command.

```{r}
# Read in the locations data frame

locs <-  read.csv("Processed_Data/TDN_camera_locations_and_covariates_cleaned.csv")

# We first want to create a data subset for each of the strata we are interested in:

# The treatment types for each Deployment.Location.ID are in the sta file
# Make an object containing all of the site ID's for the "above treeline" cameras
above_tl <- locs$location[locs$above_tl=="1"]
# And "below treeline" cameras
below_tl <- locs$location[locs$above_tl=="0"]


# Create a new empty list
inc_locations <- list()

# Only sum the data for each relevent locations
inc_locations[[1]] <- c(length(above_tl),  # First count the number of stations
                     # Then subset the detections to those stations, sum the columns, and sort the incidents
                     inc_dat[inc_dat$location %in% above_tl, sp_summary_mam$species_common_name] %>%  colSums() %>% sort(decreasing=T))


inc_locations[[2]] <- c(length(below_tl),  # Count the number of stations
                     # Then subset the detections to those stations, sum the columns, and sort the incidents
                     inc_dat[inc_dat$location %in% below_tl, sp_summary_mam$species_common_name] %>%  colSums() %>% sort(decreasing=T))

# Give them names
names(inc_locations) <- c("AboveTreeLine", "BelowTreeLine")
```

And let’s run our iNext model:

##NOTE: 2024/01/02
Getting the following error when trying to run the iNEXT model 
Error in Fun(x[[i]], q, names(x)[i]) : 
  Zero incidence frequencies in one or more sample sites
  
###UPDATE: 2024/01/02
above/below_tl is not included in cleaned covariate df and creates the above error when you try to use it. 

```{r}
out.inc <- iNEXT(inc_locations, q=0, datatype="incidence_freq")
# Sample‐size‐based R/E curves
ggiNEXT(out.inc, type=1, color.var="Assemblage") +
       labs(y="Richness", x = "Number of Cameras") + 
theme_classic() 
```

looks like below treeline is more diverse than above treeline and undersampled

## 8.4.1 Sampling duration example

If we want to explore the species accumulation patterns as a function of the number of survey nights, we can make use of the ...weekly_observations dataframes.

```{r}
#week_obs<- read.csv("Processed_Data/WildCo/_TDN_min_independent_weekly_observations.csv", header=T) 

week_obs<- read.csv("Processed_Data/wildRtrax/TDN_cam_summaries_week_mam.csv", header=T)

# Turn it into binary incidents
inc_dat <- week_obs %>% mutate(across(sp_summary_mam$species_common_name, ~+as.logical(.x))) 

inc_dat[is.na(inc_dat)]<-0

# Create a new empty list
inc_time <- list()

# Only sum the data for each relevent strata
inc_time[[1]] <- c(nrow(inc_dat[inc_dat$location %in% above_tl,]) %>% sum(inc_dat$days),  # Count the number of weeks we have data for in each strata
                     # Then subset the detections to those stations, sum the columns, and sort the incidents
                     inc_dat[inc_dat$location %in% above_tl, sp_summary_mam$species_common_name] %>%  colSums() %>% sort(decreasing=T))


  inc_time[[2]] <- c(nrow(inc_dat[inc_dat$location %in% below_tl,]) %>% sum(inc_dat$n_days_effort), inc_dat[inc_dat$location %in% below_tl, sp_summary_mam$species_common_name] %>%  colSums() %>% sort(decreasing=T))

# Give them names
names(inc_time) <- c("AboveTreeLine", "BelowTreeLine")
```

And run the model:
```{r}
out.inc <- iNEXT(inc_time, q=0, datatype="incidence_freq")
```

```{r}
# Sample‐size‐based R/E curves
ggiNEXT(out.inc, type=1, color.var="Assemblage") +
       labs(y="Richness", x = "Camera days") +
theme_classic() 
```

Which suggests the same pattern!

## 8.4.2 On your own

###dom_habitat_lcc
```{r}
# Create a new empty list
inc_time_lcc <- list()

# The treatment types for each Deployment.Location.ID are in the sta file
# Make an object containing all of the site ID's for the "Offline" cameras
TSPNF <- locs$location[locs$dom_habitat_lcc_hexagon=="TSPNF"]

#hashtagged out because no locations have these lcc landcovers as dominant
#SPTNF <- locs$location[locs$dom_habitat_lcc=="SPTNF"] 
#TSPBDF <- locs$location[locs$dom_habitat_lcc=="TSPBDF"]

MF <- locs$location[locs$dom_habitat_lcc=="MF"]
TSPS <- locs$location[locs$dom_habitat_lcc=="TSPS"]
TSPG <- locs$location[locs$dom_habitat_lcc=="TSPG"]
SPPSLM <- locs$location[locs$dom_habitat_lcc=="SPPSLM"]
SPPGLM <- locs$location[locs$dom_habitat_lcc=="SPPGLM"]
WET <- locs$location[locs$dom_habitat_lcc=="WET"]
BAR <- locs$location[locs$dom_habitat_lcc=="BAR"]
WAT <- locs$location[locs$dom_habitat_lcc=="WAT"]

# Only sum the data for each relvent locations

#inc_time_lcc[[1]] <- c(length(TSPNF), inc_dat[inc_dat$location %in% TSPNF, sp_summary$species_common_name] %>%  colSums() %>% sort(decreasing=T))
inc_time_lcc[[1]] <- c(nrow(inc_dat[inc_dat$location %in% TSPNF,]) %>% sum(inc_dat$n_days_effort), inc_dat[inc_dat$location %in% TSPNF, sp_summary_mam$species_common_name] %>%  colSums() %>% sort(decreasing=T))

#inc_locations[[2]] <- c(length(SPTNF), inc_dat[inc_dat$location %in% SPTNF, sp_summary$species_common_name] %>%  colSums() %>% sort(decreasing=T))

#inc_locations[[3]] <- c(length(TSPBDF), inc_dat[inc_dat$location %in% TSPBDF, sp_summary$species_common_name] %>%  colSums() %>% sort(decreasing=T))

#inc_time_lcc[[2]] <- c(length(MF), inc_dat[inc_dat$location %in% MF, sp_summary$species_common_name] %>%  colSums() %>% sort(decreasing=T))
inc_time_lcc[[2]] <- c(nrow(inc_dat[inc_dat$location %in% MF,]) %>% sum(inc_dat$n_days_effort), inc_dat[inc_dat$location %in% MF, sp_summary_mam$species_common_name] %>%  colSums() %>% sort(decreasing=T))

#inc_time_lcc[[3]] <- c(length(TSPS), inc_dat[inc_dat$location %in% TSPS, sp_summary$species_common_name] %>%  colSums() %>% sort(decreasing=T))
inc_time_lcc[[3]] <- c(nrow(inc_dat[inc_dat$location %in% TSPS,]) %>% sum(inc_dat$n_days_effort), inc_dat[inc_dat$location %in% TSPS, sp_summary_mam$species_common_name] %>%  colSums() %>% sort(decreasing=T))

#inc_time_lcc[[4]] <- c(length(TSPG), inc_dat[inc_dat$location %in% TSPG, sp_summary$species_common_name] %>%  colSums() %>% sort(decreasing=T))
inc_time_lcc[[4]] <- c(nrow(inc_dat[inc_dat$location %in% TSPG,]) %>% sum(inc_dat$n_days_effort), inc_dat[inc_dat$location %in% TSPG, sp_summary_mam$species_common_name] %>%  colSums() %>% sort(decreasing=T))

#inc_time_lcc[[5]] <- c(length(SPPSLM), inc_dat[inc_dat$location %in% SPPSLM, sp_summary$species_common_name] %>%  colSums() %>% sort(decreasing=T))
inc_time_lcc[[5]] <- c(nrow(inc_dat[inc_dat$location %in% SPPSLM,]) %>% sum(inc_dat$n_days_effort), inc_dat[inc_dat$location %in% SPPSLM, sp_summary_mam$species_common_name] %>%  colSums() %>% sort(decreasing=T))

#inc_time_lcc[[6]] <- c(length(SPPGLM), inc_dat[inc_dat$location %in% SPPGLM, sp_summary$species_common_name] %>%  colSums() %>% sort(decreasing=T))
inc_time_lcc[[6]] <- c(nrow(inc_dat[inc_dat$location %in% SPPGLM,]) %>% sum(inc_dat$n_days_effort), inc_dat[inc_dat$location %in% SPPGLM, sp_summary_mam$species_common_name] %>%  colSums() %>% sort(decreasing=T))

#inc_time_lcc[[7]] <- c(length(WET), inc_dat[inc_dat$location %in% WET, sp_summary$species_common_name] %>%  colSums() %>% sort(decreasing=T))
inc_time_lcc[[7]] <- c(nrow(inc_dat[inc_dat$location %in% WET,]) %>% sum(inc_dat$n_days_effort), inc_dat[inc_dat$location %in% WET, sp_summary_mam$species_common_name] %>%  colSums() %>% sort(decreasing=T))

#inc_time_lcc[[8]] <- c(length(BAR), inc_dat[inc_dat$location %in% BAR, sp_summary$species_common_name] %>%  colSums() %>% sort(decreasing=T))
inc_time_lcc[[8]] <- c(nrow(inc_dat[inc_dat$location %in% BAR,]) %>% sum(inc_dat$n_days_effort), inc_dat[inc_dat$location %in% BAR, sp_summary_mam$species_common_name] %>%  colSums() %>% sort(decreasing=T))

#inc_time_lcc[[9]] <- c(length(WAT), inc_dat[inc_dat$location %in% WAT, sp_summary$species_common_name] %>%  colSums() %>% sort(decreasing=T))
inc_time_lcc[[9]] <- c(nrow(inc_dat[inc_dat$location %in% WAT,]) %>% sum(inc_dat$n_days_effort), inc_dat[inc_dat$location %in% WAT, sp_summary_mam$species_common_name] %>%  colSums() %>% sort(decreasing=T))

# Give them names
names(inc_time_lcc) <- c("Temperate.or.sub-polar.needleleaf.forest","Mixed.forest","Temperate.or.sub-polar.shrubland","Temperate.or.sub-polar.grassland","Sub-polar.or.polar.shrubland-lichen-moss","Sub-polar.or.polar.grassland-lichen-moss","Wetland","Barren.lands","Water")
```


```{r}
out.inc <- iNEXT(inc_time_lcc, q=0, datatype="incidence_freq")
# Sample‐size‐based R/E curves
ggiNEXT(out.inc, type=1, color.var="Assemblage",facet.var = "Assemblage") +
       labs(y="Richness", x = "Camera days") +
theme_classic() 
```

###dom_habitat_lcc_hexagon
```{r}
# Create a new empty list
inc_time_lcc_hex <- list()

# The treatment types for each Deployment.Location.ID are in the sta file
# Make an object containing all of the site ID's for the "Offline" cameras
TSPNF <- locs$location[locs$dom_habitat_lcc_hexagon=="TSPNF"]

#hashtagged out because no locations have these lcc landcovers as dominant
#SPTNF <- locs$location[locs$dom_habitat_lcc=="SPTNF"] 
#TSPBDF <- locs$location[locs$dom_habitat_lcc=="TSPBDF"]

MF <- locs$location[locs$dom_habitat_lcc_hexagon=="MF"]
TSPS <- locs$location[locs$dom_habitat_lcc_hexagon=="TSPS"]
TSPG <- locs$location[locs$dom_habitat_lcc_hexagon=="TSPG"]
SPPSLM <- locs$location[locs$dom_habitat_lcc_hexagon=="SPPSLM"]
SPPGLM <- locs$location[locs$dom_habitat_lcc_hexagon=="SPPGLM"]
WET <- locs$location[locs$dom_habitat_lcc_hexagon=="WET"]
#BAR <- locs$location[locs$dom_habitat_lcc_hexagon=="BAR"]
WAT <- locs$location[locs$dom_habitat_lcc_hexagon=="WAT"]

# Only sum the data for each relvent locations

#inc_time_lcc[[1]] <- c(length(TSPNF), inc_dat[inc_dat$location %in% TSPNF, sp_summary$species_common_name] %>%  colSums() %>% sort(decreasing=T))
inc_time_lcc_hex[[1]] <- c(nrow(inc_dat[inc_dat$location %in% TSPNF,]) %>% sum(inc_dat$n_days_effort), inc_dat[inc_dat$location %in% TSPNF, sp_summary_mam$species_common_name] %>%  colSums() %>% sort(decreasing=T))

#inc_locations[[2]] <- c(length(SPTNF), inc_dat[inc_dat$location %in% SPTNF, sp_summary$species_common_name] %>%  colSums() %>% sort(decreasing=T))

#inc_locations[[3]] <- c(length(TSPBDF), inc_dat[inc_dat$location %in% TSPBDF, sp_summary$species_common_name] %>%  colSums() %>% sort(decreasing=T))

#inc_time_lcc[[2]] <- c(length(MF), inc_dat[inc_dat$location %in% MF, sp_summary$species_common_name] %>%  colSums() %>% sort(decreasing=T))
inc_time_lcc_hex[[2]] <- c(nrow(inc_dat[inc_dat$location %in% MF,]) %>% sum(inc_dat$n_days_effort), inc_dat[inc_dat$location %in% MF, sp_summary_mam$species_common_name] %>%  colSums() %>% sort(decreasing=T))

#inc_time_lcc[[3]] <- c(length(TSPS), inc_dat[inc_dat$location %in% TSPS, sp_summary$species_common_name] %>%  colSums() %>% sort(decreasing=T))
inc_time_lcc_hex[[3]] <- c(nrow(inc_dat[inc_dat$location %in% TSPS,]) %>% sum(inc_dat$n_days_effort), inc_dat[inc_dat$location %in% TSPS, sp_summary_mam$species_common_name] %>%  colSums() %>% sort(decreasing=T))

#inc_time_lcc[[4]] <- c(length(TSPG), inc_dat[inc_dat$location %in% TSPG, sp_summary$species_common_name] %>%  colSums() %>% sort(decreasing=T))
inc_time_lcc_hex[[4]] <- c(nrow(inc_dat[inc_dat$location %in% TSPG,]) %>% sum(inc_dat$n_days_effort), inc_dat[inc_dat$location %in% TSPG, sp_summary_mam$species_common_name] %>%  colSums() %>% sort(decreasing=T))

#inc_time_lcc[[5]] <- c(length(SPPSLM), inc_dat[inc_dat$location %in% SPPSLM, sp_summary$species_common_name] %>%  colSums() %>% sort(decreasing=T))
inc_time_lcc_hex[[5]] <- c(nrow(inc_dat[inc_dat$location %in% SPPSLM,]) %>% sum(inc_dat$n_days_effort), inc_dat[inc_dat$location %in% SPPSLM, sp_summary_mam$species_common_name] %>%  colSums() %>% sort(decreasing=T))

#inc_time_lcc[[6]] <- c(length(SPPGLM), inc_dat[inc_dat$location %in% SPPGLM, sp_summary$species_common_name] %>%  colSums() %>% sort(decreasing=T))
inc_time_lcc_hex[[6]] <- c(nrow(inc_dat[inc_dat$location %in% SPPGLM,]) %>% sum(inc_dat$n_days_effort), inc_dat[inc_dat$location %in% SPPGLM, sp_summary_mam$species_common_name] %>%  colSums() %>% sort(decreasing=T))

#inc_time_lcc[[7]] <- c(length(WET), inc_dat[inc_dat$location %in% WET, sp_summary$species_common_name] %>%  colSums() %>% sort(decreasing=T))
inc_time_lcc_hex[[7]] <- c(nrow(inc_dat[inc_dat$location %in% WET,]) %>% sum(inc_dat$n_days_effort), inc_dat[inc_dat$location %in% WET, sp_summary_mam$species_common_name] %>%  colSums() %>% sort(decreasing=T))

#inc_time_lcc[[8]] <- c(length(BAR), inc_dat[inc_dat$location %in% BAR, sp_summary$species_common_name] %>%  colSums() %>% sort(decreasing=T))
#inc_time_lcc_hex[[8]] <- c(nrow(inc_dat[inc_dat$location %in% BAR,]) %>% sum(inc_dat$days), inc_dat[inc_dat$location %in% BAR, sp_summary_mam$species_common_name] %>%  colSums() %>% sort(decreasing=T))

#inc_time_lcc[[9]] <- c(length(WAT), inc_dat[inc_dat$location %in% WAT, sp_summary$species_common_name] %>%  colSums() %>% sort(decreasing=T))
inc_time_lcc_hex[[8]] <- c(nrow(inc_dat[inc_dat$location %in% WAT,]) %>% sum(inc_dat$n_days_effort), inc_dat[inc_dat$location %in% WAT, sp_summary_mam$species_common_name] %>%  colSums() %>% sort(decreasing=T))

# Give them names
names(inc_time_lcc_hex) <- c("Temperate.or.sub-polar.needleleaf.forest","Mixed.forest","Temperate.or.sub-polar.shrubland","Temperate.or.sub-polar.grassland","Sub-polar.or.polar.shrubland-lichen-moss","Sub-polar.or.polar.grassland-lichen-moss","Wetland","Water")
```


```{r}
out.inc <- iNEXT(inc_time_lcc_hex, q=0, datatype="incidence_freq")
# Sample‐size‐based R/E curves
ggiNEXT(out.inc, type=1, color.var="Assemblage",facet.var = "Assemblage") +
       labs(y="Richness", x = "Camera days") +
theme_classic() 
```


# 8.5 Other diversity metrics

## 8.5.1 Simpson and Shannon

One issue with species richness assessments is that they weight all species equally, thus a community with 12 species all present in equal abundances will give you the same richness value as a high skewed community with one highly abundant species, and 11 very rare ones. Consequently, you might want to estimate species diversity.

Luckily, the iNEXT package is well suited for comparisons of diversity indices through the use of hill numbers - of which the ‘q’ value represents the traditional Shannon (q=1) and Simpson (q=2) diversity indices (species richness: q = 0). Note Increasing values of q reduces the influence of rare species on your estimate of community diversity.

For example, we might want to compare the species diversity across our two focal strata:

```{r}
# We also introduce the object t -> which reflects the range of values over which you want to predict species richness
out <- iNEXT(inc_time, q=c(0,1,2) ,datatype="incidence_freq" )

ggiNEXT(out, type=1, facet.var="Order.q", color.var="Assemblage") + theme_classic() 
```

The plot above shows that the differences between our two strata remain across increasing q values (suggesting that the different inst just driven by several rarely encountered species).

Point estimates and their confidence intervals can also be extracted from iNEXT model objects - but it does require a little data wrangling. For example, if we wanted to directly compare the diversity estimates of our strata at 1000 survey units:

```{r}
# To generate predictions for specific amounts of survey effort, we make use of the variable t
# T specifies the values you want iNEXt to calculate diversity for
out <- iNEXT(inc_time, q=c(0,1,2) ,datatype="incidence_freq", size=c(1000))

# The lapply function applies the same logic across elements in a list
point_estimate <- out$iNextEst$size_based[out$iNextEst$size_based$t==1000,] 
point_estimate
```

```{r}
# Make a nice ggplot!
ggplot(point_estimate, aes(x=c(-0.2,0.8, 1.8,
                               0,1,2,
                                0.2, 1.2, 2.2), y=qD, colour=Assemblage)) + 
       theme_classic() +
       #scale_x_discrete(breaks=c("1","2"),labels= c("1","2")) +
       geom_errorbar(aes(ymin=qD.LCL, ymax=qD.UCL), width=.01) +
       labs(y="Diversity", x = "Diversity at 1000 survey days") +
       geom_point() 
```

# 8.6 Community structure

One of the shortfalls in the diversity index approaches is that you can compare two sites with completely different mammal assemblages, but identical diversity estimates! So we would conclude that the two are the same, however,in reality their compositions are totally different. Another way to assess community structure is with ordination methods (e.g non-metric multidimensional scaling or NMDS).

Luckily a basic NMDS is very easy to run from our ...total_observations dataframe:

```{r}
#install.packages("vegan")
library(vegan)
# Import your count data
#total_obs <- read.csv("data/processed_data/AlgarRestorationProject_30min_independent_total_observations.csv", header=T)

#Import the location and covariate data
#locs <-  read.csv("data/processed_data/AlgarRestorationProject_camera_locations_and_covariates.csv")

# Add the covariates to your total_obs dataframe
dat <- left_join(total_obs, locs)

# Convert to categorical factors
dat <- dat %>% 
            mutate_if(is.character,as.factor)

# Subset to just the count columns
counts <- dat[,sp_summary_mam$species_common_name]

# Covert it into a matrix
m_counts <-  as.matrix(counts)
```

We are now ready to run our NMDS model:

##NOTE: 02/08/2023; can't get this code to work

Error in if (max(dis) > maxdis + sqrt(.Machine$double.eps)) { : 
  missing value where TRUE/FALSE needed
  
```{r}
set.seed(123) # To make sure we all get the same result

# run metaMDS on the count matrix using the " Bray-Curtis dissimilarity" note others are available
nmds = metaMDS(m_counts,          # The count matrix
               distance = "bray", # The method of solving 
               trace=1 )           # Suppress the output - trace=1 is more informative


nmds
```

## 8.6.1 Extracting data for plotting

To make a nice plot of the NMDS data we need to learn how to extract the data from it:

```{r}
# Make a dataframe out of the x and Y scores
site.scores <- as.data.frame(scores(nmds)$sites)
species.scores <- as.data.frame(scores(nmds)$species)

# Add in the covariate data
#add covariate columns to data frame 
site.scores$location <- dat$location
site.scores$feature_type <- dat$feature_type

# Assign colors to our feature_types using viridis
# then use the turbo() function to assign each level a color
col.cat <- cividis(length(levels(dat$feature_type)))
# then we apply it to the dataframe
dat$colours <- col.cat[dat$feature_type]
```

Lets make a plot in base R using the default plotting functions:

```{r}
par(mfrow=c(1,1))
# Make an empty plot type="n
ordiplot(nmds,type="n", las=1,
         xlim=c(-1.5,1.2))
# Add an elipse corresponding to each site
ordiellipse(nmds, groups=dat$feature_type,
            col=col.cat, lwd=2)
# Add the species loadings
orditorp(nmds,display="species",col="red",air=0.5)
# Add the site loadings
points(site.scores$NMDS1, site.scores$NMDS2, col=dat$colours, pch=19)
# Add a legend
legend("topleft", levels(dat$feature_type), col=col.cat, pch=19 )
```

